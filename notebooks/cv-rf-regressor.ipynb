{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d2babd4-19b8-4bae-af9c-23ce9abc4776",
   "metadata": {},
   "source": [
    "# Tuning RandomForestRegressor using CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3c540f-e04a-4331-b007-c48e8a18d1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b94f372-1715-4838-a244-430c7f1b6f77",
   "metadata": {},
   "source": [
    "## Create synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabb9de1-a520-46db-9023-0b1989b7acac",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 50000\n",
    "n_cols = 300\n",
    "dtype='float32'\n",
    "X, y = make_regression(n_samples=n_rows, n_features=n_cols, random_state=1)\n",
    "X = X.astype(dtype)\n",
    "y = y.astype(dtype)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51b09b0-c869-40d2-aae7-ebb6757c505f",
   "metadata": {},
   "source": [
    "## Convert dataset to Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e1aaf7-3d70-457f-88b7-293511518424",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_data_train = pd.DataFrame({\"features\": list(X_train), \"label\": y_train})\n",
    "pd_data_test = pd.DataFrame({\"features\": list(X_test), \"label\": y_test})\n",
    "df_train = spark.createDataFrame(pd_data_train)\n",
    "df_test = spark.createDataFrame(pd_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0b023f-3d64-48de-9d6b-7f8bcf35dce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd13fa4-a418-4daa-b534-453f9dd4bd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rf_regressor(estimator_class):\n",
    "    return ( estimator_class()\n",
    "                .setFeaturesCol(\"features\")\n",
    "                .setLabelCol(\"label\")\n",
    "                .setFeatureSubsetStrategy(\"all\")\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db226810-a65f-44fd-a4b1-c296b6ed3605",
   "metadata": {},
   "source": [
    "## CrossValidator builder\n",
    "\n",
    "We will use this function to build both the Spark RAPIDS ML (GPU) and Spark ML (CPU) CrossValidator objects,\n",
    "demonstrating the common API, and verify they yield similar performance on our synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ef5f56-8463-4d00-a97a-fd88f2350637",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "\n",
    "def create_crossvalidator(cv_class, rf_regressor_class):\n",
    "    # instantiate evaluator\n",
    "    evaluator = RegressionEvaluator().setLabelCol(\"label\")\n",
    "\n",
    "    # instantiate RandomForestRegressor\n",
    "    rf_reg = (\n",
    "        rf_regressor_class()\n",
    "        .setFeaturesCol(\"features\")\n",
    "        .setLabelCol(\"label\")\n",
    "        .setFeatureSubsetStrategy(\"all\")\n",
    "        )\n",
    "\n",
    "    # create the parameters to be tuned\n",
    "    grid = (\n",
    "        ParamGridBuilder()\n",
    "        .addGrid(rf_reg.maxDepth, [5, 8])\n",
    "        .addGrid(rf_reg.maxBins, [32, 64])\n",
    "        .build()\n",
    "    )\n",
    "\n",
    "    # instantiate the CrossValidator\n",
    "    cv = (\n",
    "        cv_class()\n",
    "        .setEstimator(rf_reg)\n",
    "        .setEvaluator(evaluator)\n",
    "        .setEstimatorParamMaps(grid)\n",
    "        .setNumFolds(3)\n",
    "    )\n",
    "    return cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3eca37d-114e-4b26-851d-104fbe37d591",
   "metadata": {},
   "source": [
    "## Spark RAPIDS ML (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7176f7b4-75ed-44b2-bbce-852f4a5b487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spark_rapids_ml.tuning import CrossValidator\n",
    "from spark_rapids_ml.regression import RandomForestRegressor\n",
    "\n",
    "cross_validator = create_crossvalidator(CrossValidator, RandomForestRegressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c246ca5-b647-47f0-9489-2f13d57f0d7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T02:33:05.091392Z",
     "iopub.status.busy": "2023-06-29T02:33:05.090587Z",
     "iopub.status.idle": "2023-06-29T02:33:05.100929Z",
     "shell.execute_reply": "2023-06-29T02:33:05.098679Z",
     "shell.execute_reply.started": "2023-06-29T02:33:05.091321Z"
    }
   },
   "source": [
    "### tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdf5c34-82be-46b3-b20d-1118dc4bc2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "cv_model = cross_validator.fit(df_train)\n",
    "print(f\"Tuning took: {time.time() - start_time} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d1d6c2-fc08-40bb-b19a-b1fca2a8915b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df = cv_model.transform(df_test)\n",
    "evaluator = (\n",
    "    RegressionEvaluator()\n",
    "    .setPredictionCol(\"prediction\")\n",
    "    .setLabelCol(\"label\")\n",
    ")\n",
    "print(f\"rmse: {evaluator.evaluate(transformed_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed420b5f-2ad3-493a-a1e3-7f5f3e52b840",
   "metadata": {},
   "source": [
    "Check that the RMSE is smaller than the standard deviation of the label column, indicating that the model is making non-trivial predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470e5704-1430-4126-afc1-b8179daab8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import stddev\n",
    "print(f'label stddev: {transformed_df.select(stddev(\"label\").alias(\"stddev\")).toPandas()[\"stddev\"][0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c38ab24-263d-4968-8d7a-bec0be052130",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T02:40:31.279827Z",
     "iopub.status.busy": "2023-06-29T02:40:31.278357Z",
     "iopub.status.idle": "2023-06-29T02:40:31.288403Z",
     "shell.execute_reply": "2023-06-29T02:40:31.286034Z",
     "shell.execute_reply.started": "2023-06-29T02:40:31.279753Z"
    }
   },
   "source": [
    "## Spark ML (CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5976c57-8d7a-41c1-8a3a-ffcccfa49138",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "\n",
    "cross_validator = create_crossvalidator(CrossValidator, RandomForestRegressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e30396f-3693-4759-b8e2-ac9ebeeadc08",
   "metadata": {},
   "source": [
    "### Tuning\n",
    "\n",
    "Convert array sql type to VectorUDT expected by Spark ML (Note: Spark RAPIDS ML also accepts VectorUDT Dataframes in addition to array type Dataframe above, along with a scalar column format - see docs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ba836f-90fe-4a29-b51c-525817890e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.functions import array_to_vector\n",
    "\n",
    "vector_df_train = df_train.select(array_to_vector(df_train.features).alias(\"features\"),\"label\")\n",
    "vector_df_test = df_test.select(array_to_vector(df_test.features).alias(\"features\"),\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f97d4e6-fcd2-4ab5-8345-b5d1ec86bddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "cv_model = cross_validator.fit(vector_df_train)\n",
    "print(f\"Tuning took: {time.time() - start_time} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a9afd4-6886-45fc-8e67-23d96496f4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = (\n",
    "    RegressionEvaluator()\n",
    "    .setPredictionCol(\"prediction\")\n",
    "    .setLabelCol(\"label\")\n",
    ")\n",
    "print(f\"rmse: {evaluator.evaluate(cv_model.transform(vector_df_test))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-23.04",
   "language": "python",
   "name": "rapids-23.04"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
