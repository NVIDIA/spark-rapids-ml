{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4319ad5-7b8d-47ae-8227-230ce6ee40ec",
   "metadata": {},
   "source": [
    "# Pyspark Compatibility Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df866f0-8ca1-458a-a427-f01ffcdd77ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PCA\n",
    "From: https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.PCA.html#pyspark.ml.feature.PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d73ca9e5-d033-435b-8f8c-2aa64ee2a251",
   "metadata": {},
   "outputs": [],
   "source": [
    "PYSPARK = False\n",
    "SPARK_RAPIDS_ML = not PYSPARK\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65bb00c7-7aba-45a6-8998-3182051b2f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PYSPARK:\n",
    "    from pyspark.ml.feature import PCA, PCAModel\n",
    "else:\n",
    "    from spark_rapids_ml.feature import PCA, PCAModel\n",
    "\n",
    "from pyspark.ml.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f56d981-48b1-4daf-acb6-8ba4fdba06a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(SparseVector(5, {1: 1.0, 3: 7.0}),),\n",
       " (DenseVector([2.0, 0.0, 3.0, 4.0, 5.0]),),\n",
       " (DenseVector([4.0, 0.0, 0.0, 6.0, 7.0]),)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [(Vectors.sparse(5, [(1, 1.0), (3, 7.0)]),),\n",
    "        (Vectors.dense([2.0, 0.0, 3.0, 4.0, 5.0]),),\n",
    "        (Vectors.dense([4.0, 0.0, 0.0, 6.0, 7.0]),)]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ae01021-9ccd-4545-a054-f61c39c6b224",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "| (5,[1,3],[1.0,7.0])|\n",
      "|[2.0,0.0,3.0,4.0,...|\n",
      "|[4.0,0.0,0.0,6.0,...|\n",
      "+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StructType([StructField('features', VectorUDT(), True)])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.createDataFrame(data,[\"features\"])\n",
    "df.show(); df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63028b55-5642-4552-9c3d-347e26466956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputCol: input column name. (undefined)\n",
      "inputCols: input column names. (undefined)\n",
      "k: the number of principal components (undefined)\n",
      "num_workers: (cuML) number of Spark cuML workers, where each cuML worker corresponds to one Spark task. (default: 1)\n",
      "outputCol: output column name. (default: PCA_fb9b083f9099__output)\n",
      "outputCols: output column names. (undefined)\n"
     ]
    }
   ],
   "source": [
    "pca = PCA()\n",
    "print(pca.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2830b959-ff86-40f8-8595-d1ec683eb5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA_a3141401b5b0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(k=2, inputCol=\"features\")\n",
    "# pca = PCA(k=2, inputCol=\"features\", n_components=3)\n",
    "# pca = PCA(inputCol=\"features\", n_components=3)\n",
    "pca.setOutputCol(\"pca_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "966803e8-8a96-4f0f-a046-0eecdd0c0769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputCol: input column name. (current: features)\n",
      "inputCols: input column names. (undefined)\n",
      "k: the number of principal components (current: 2)\n",
      "num_workers: (cuML) number of Spark cuML workers, where each cuML worker corresponds to one Spark task. (default: 1)\n",
      "outputCol: output column name. (default: PCA_a3141401b5b0__output, current: pca_features)\n",
      "outputCols: output column names. (undefined)\n"
     ]
    }
   ],
   "source": [
    "print(pca.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cc4a9cc-fd81-4fe5-9eee-dd8949bed51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k': 'n_components'}\n",
      "{'n_components': 2, 'svd_solver': 'auto', 'verbose': False, 'whiten': False}\n"
     ]
    }
   ],
   "source": [
    "if SPARK_RAPIDS_ML:\n",
    "    print(pca._param_mapping())\n",
    "    print(pca.cuml_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63804960-9350-4852-a955-fa8ee7a11edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA_a3141401b5b0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.setK(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90926a3d-fe7b-48d2-99b5-960484b165ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputCol: input column name. (current: features)\n",
      "inputCols: input column names. (undefined)\n",
      "k: the number of principal components (current: 3)\n",
      "num_workers: (cuML) number of Spark cuML workers, where each cuML worker corresponds to one Spark task. (default: 1)\n",
      "outputCol: output column name. (default: PCA_a3141401b5b0__output, current: pca_features)\n",
      "outputCols: output column names. (undefined)\n"
     ]
    }
   ],
   "source": [
    "print(pca.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6950622c-c249-4a9d-894e-78cfe9734b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_components': 3, 'svd_solver': 'auto', 'verbose': False, 'whiten': False}\n"
     ]
    }
   ],
   "source": [
    "if SPARK_RAPIDS_ML:\n",
    "    print(pca.cuml_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1cc9410-d6ea-4933-ae9c-ceb65833ad34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA_a3141401b5b0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.setK(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a61234f5-070c-4fb4-ad2f-c0b741cf79ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model = pca.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3e74f81-476d-4423-bbe5-46b59480d749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.getK()\n",
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a70f79c-2f66-4a5e-82a9-c2cfe02f490e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCAModel_f9db869bf701"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.setOutputCol(\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11ed38a9-743e-4598-9ccf-dc28b2e78ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputCol: input column name. (current: features)\n",
      "inputCols: input column names. (undefined)\n",
      "k: the number of principal components (current: 2)\n",
      "num_workers: (cuML) number of Spark cuML workers, where each cuML worker corresponds to one Spark task. (default: 1)\n",
      "outputCol: output column name. (default: PCA_a3141401b5b0__output, current: output)\n",
      "outputCols: output column names. (undefined)\n"
     ]
    }
   ],
   "source": [
    "print(model.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95db536e-ccda-4380-93cd-4d313365a697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_components': 2, 'svd_solver': 'auto', 'verbose': False, 'whiten': False}\n"
     ]
    }
   ],
   "source": [
    "if SPARK_RAPIDS_ML:\n",
    "    print(model.cuml_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08e8b235-e7a3-4694-9a62-46e9ec93094d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-1.6485728230896184, -4.013282697765595]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transform(df).collect()[0].output\n",
    "# DenseVector([1.648..., -4.013...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c1db46f-72f8-43f6-aaf8-6aebd4c7318a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.7944, 0.2056])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.explainedVariance\n",
    "# DenseVector([0.794..., 0.205...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99f3e554-fb17-44f5-bad2-ae8b306167ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseMatrix(5, 2, [0.4486, -0.133, 0.1252, -0.2165, 0.8477, -0.2842, -0.0562, 0.7636, -0.5653, -0.1156], False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pc\n",
    "# DenseMatrix(5, 2, [-0.4486, 0.133, -0.1252, 0.2165, -0.8477, -0.2842, -0.0562, 0.7636, -0.5653, -0.1156], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8da1934e-cd40-40d5-8f56-7d711ed06620",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_path = \"/tmp\"\n",
    "pcaPath = temp_path + \"/pca\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e55bfaa3-a0c4-4f54-9893-79f8f82410bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(pcaPath, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "deea9119-6f4d-4233-8e6a-28e5ccee6b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.save(pcaPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cd390f1-c709-4f4d-9a83-f86b1e0573e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadedPca = PCA.load(pcaPath)\n",
    "loadedPca.getK() == pca.getK()\n",
    "# True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1cb9a5d4-a09f-435e-933b-59ceadbf92d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_components': 2, 'svd_solver': 'auto', 'verbose': False, 'whiten': False}\n",
      "{'n_components': 2, 'svd_solver': 'auto', 'verbose': False, 'whiten': False}\n"
     ]
    }
   ],
   "source": [
    "# confirm saved estimator cuml_params\n",
    "if SPARK_RAPIDS_ML:\n",
    "    print(pca.cuml_params)\n",
    "    print(loadedPca.cuml_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02a6c8a1-d5d8-40af-9804-d600e503bd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = temp_path + \"/pca-model\"\n",
    "shutil.rmtree(modelPath, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "353986ab-fba7-48a7-9f97-2db5ce1490ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(modelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47aad8bd-b4bb-410d-873d-bdc9ba9d0c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadedModel = PCAModel.load(modelPath)\n",
    "loadedModel.pc == model.pc\n",
    "# True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e57e11e-4ac5-4145-9351-6577e2e14e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_components': 2, 'svd_solver': 'auto', 'verbose': False, 'whiten': False}\n",
      "{'n_components': 2, 'svd_solver': 'auto', 'verbose': False, 'whiten': False}\n"
     ]
    }
   ],
   "source": [
    "# confirm saved model cuml_params\n",
    "if SPARK_RAPIDS_ML:\n",
    "    print(model.cuml_params)\n",
    "    print(loadedModel.cuml_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44681be2-a2a5-4111-8fb0-46a77dfa61dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadedModel.explainedVariance == model.explainedVariance\n",
    "# True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "081bb7ef-86b6-45e3-88d8-cea892777bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadedModel.transform(df).take(1) == model.transform(df).take(1)\n",
    "# True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950f3f77-2016-43ae-8b8c-c8fd2b7117e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## KMeans\n",
    "From: https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.clustering.KMeans.html#pyspark.ml.clustering.KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "304140a6-06d8-4d53-b3c1-576756f2a422",
   "metadata": {},
   "outputs": [],
   "source": [
    "PYSPARK = False\n",
    "SPARK_RAPIDS_ML = not PYSPARK\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4cc1d3be-9835-4157-b836-a49f4a6d0577",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PYSPARK:\n",
    "    from pyspark.ml.clustering import KMeans, KMeansModel\n",
    "else:\n",
    "    from spark_rapids_ml.clustering import KMeans, KMeansModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f5f09d6f-66cd-4b1e-9926-b9fe0eb08119",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c1b3d2b2-91da-4ec5-abbe-19667ac0f992",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(Vectors.dense([0.0, 0.0]), 2.0), (Vectors.dense([1.0, 1.0]), 2.0),\n",
    "        (Vectors.dense([9.0, 8.0]), 2.0), (Vectors.dense([8.0, 9.0]), 2.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d8017c4-9ca0-40ec-be4c-15aef93368ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "| features|weighCol|\n",
      "+---------+--------+\n",
      "|[0.0,0.0]|     2.0|\n",
      "|[1.0,1.0]|     2.0|\n",
      "|[9.0,8.0]|     2.0|\n",
      "|[8.0,9.0]|     2.0|\n",
      "+---------+--------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StructType([StructField('features', VectorUDT(), True), StructField('weighCol', DoubleType(), True)])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.createDataFrame(data, [\"features\", \"weighCol\"]).repartition(1)\n",
    "df.show(); df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b77ee895-d2b7-4a6c-a6f1-d66eb10f7b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d6c28d8-7ecb-47db-a016-6d8211abb638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distanceMeasure: the distance measure. Supported options: 'euclidean' and 'cosine'. (default: euclidean)\n",
      "featuresCol: features column name. (default: features)\n",
      "featuresCols: features column names for multi-column input. (undefined)\n",
      "initMode: The initialization algorithm. This can be either \"random\" to choose random points as initial cluster centers, or \"k-means||\" to use a parallel variant of k-means++ (default: k-means||)\n",
      "initSteps: The number of steps for k-means|| initialization mode. Must be > 0. (default: 2)\n",
      "k: The number of clusters to create. Must be > 1. (default: 2)\n",
      "maxBlockSizeInMB: maximum memory in MB for stacking input data into blocks. Data is stacked within partitions. If more than remaining data size in a partition then it is adjusted to the data size. Default 0.0 represents choosing optimal value, depends on specific algorithm. Must be >= 0. (default: 0.0)\n",
      "maxIter: max number of iterations (>= 0). (default: 20)\n",
      "num_workers: (cuML) number of Spark cuML workers, where each cuML worker corresponds to one Spark task. (default: 1)\n",
      "predictionCol: prediction column name. (default: prediction)\n",
      "seed: random seed. (default: 1909113551)\n",
      "solver: The solver algorithm for optimization. Supported options: auto, row, block. (default: auto)\n",
      "tol: the convergence tolerance for iterative algorithms (>= 0). (default: 0.0001)\n",
      "weightCol: weight column name. If this is not set or empty, we treat all instance weights as 1.0. (undefined)\n"
     ]
    }
   ],
   "source": [
    "print(kmeans.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "edaaa7b6-1e44-42e8-bc34-e2c810a41689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'distanceMeasure': None, 'k': 'n_clusters', 'initSteps': '', 'maxIter': 'max_iter', 'seed': 'random_state', 'tol': 'tol', 'weightCol': None}\n",
      "{'n_clusters': 2, 'max_iter': 20, 'tol': 0.0001, 'verbose': False, 'random_state': 1909113551, 'init': 'scalable-k-means++', 'n_init': 1, 'oversampling_factor': 2.0, 'max_samples_per_batch': 32768}\n"
     ]
    }
   ],
   "source": [
    "if SPARK_RAPIDS_ML:\n",
    "    print(kmeans._param_mapping())\n",
    "    print(kmeans.cuml_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "238bde84-42a4-4280-9f7e-c0fc678128e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(k=2)\n",
    "kmeans.setSeed(1)\n",
    "kmeans.setMaxIter(10)\n",
    "\n",
    "if PYSPARK:\n",
    "    kmeans.setWeightCol(\"weighCol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c658398a-0285-4438-9abe-0ccd196f625a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distanceMeasure: the distance measure. Supported options: 'euclidean' and 'cosine'. (default: euclidean)\n",
      "featuresCol: features column name. (default: features)\n",
      "featuresCols: features column names for multi-column input. (undefined)\n",
      "initMode: The initialization algorithm. This can be either \"random\" to choose random points as initial cluster centers, or \"k-means||\" to use a parallel variant of k-means++ (default: k-means||)\n",
      "initSteps: The number of steps for k-means|| initialization mode. Must be > 0. (default: 2)\n",
      "k: The number of clusters to create. Must be > 1. (default: 2, current: 2)\n",
      "maxBlockSizeInMB: maximum memory in MB for stacking input data into blocks. Data is stacked within partitions. If more than remaining data size in a partition then it is adjusted to the data size. Default 0.0 represents choosing optimal value, depends on specific algorithm. Must be >= 0. (default: 0.0)\n",
      "maxIter: max number of iterations (>= 0). (default: 20, current: 10)\n",
      "num_workers: (cuML) number of Spark cuML workers, where each cuML worker corresponds to one Spark task. (default: 1)\n",
      "predictionCol: prediction column name. (default: prediction)\n",
      "seed: random seed. (default: 1909113551, current: 1)\n",
      "solver: The solver algorithm for optimization. Supported options: auto, row, block. (default: auto)\n",
      "tol: the convergence tolerance for iterative algorithms (>= 0). (default: 0.0001)\n",
      "weightCol: weight column name. If this is not set or empty, we treat all instance weights as 1.0. (undefined)\n"
     ]
    }
   ],
   "source": [
    "print(kmeans.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "26521ef4-8139-47c0-ad24-0b9c5f786139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_clusters': 2, 'max_iter': 10, 'tol': 0.0001, 'verbose': False, 'random_state': 1, 'init': 'scalable-k-means++', 'n_init': 1, 'oversampling_factor': 2.0, 'max_samples_per_batch': 32768}\n"
     ]
    }
   ],
   "source": [
    "if SPARK_RAPIDS_ML:\n",
    "    print(kmeans.cuml_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94b3278f-d5ee-4680-89be-b849b9991a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.getMaxIter()\n",
    "# 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f137bb82-8bd3-4909-9df5-8be5a2d2fd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.clear(kmeans.maxIter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c155513a-4386-4f08-b8f6-0b9ef2c46947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distanceMeasure: the distance measure. Supported options: 'euclidean' and 'cosine'. (default: euclidean)\n",
      "featuresCol: features column name. (default: features)\n",
      "featuresCols: features column names for multi-column input. (undefined)\n",
      "initMode: The initialization algorithm. This can be either \"random\" to choose random points as initial cluster centers, or \"k-means||\" to use a parallel variant of k-means++ (default: k-means||)\n",
      "initSteps: The number of steps for k-means|| initialization mode. Must be > 0. (default: 2)\n",
      "k: The number of clusters to create. Must be > 1. (default: 2, current: 2)\n",
      "maxBlockSizeInMB: maximum memory in MB for stacking input data into blocks. Data is stacked within partitions. If more than remaining data size in a partition then it is adjusted to the data size. Default 0.0 represents choosing optimal value, depends on specific algorithm. Must be >= 0. (default: 0.0)\n",
      "maxIter: max number of iterations (>= 0). (default: 20)\n",
      "num_workers: (cuML) number of Spark cuML workers, where each cuML worker corresponds to one Spark task. (default: 1)\n",
      "predictionCol: prediction column name. (default: prediction)\n",
      "seed: random seed. (default: 1909113551, current: 1)\n",
      "solver: The solver algorithm for optimization. Supported options: auto, row, block. (default: auto)\n",
      "tol: the convergence tolerance for iterative algorithms (>= 0). (default: 0.0001)\n",
      "weightCol: weight column name. If this is not set or empty, we treat all instance weights as 1.0. (undefined)\n"
     ]
    }
   ],
   "source": [
    "print(kmeans.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cc9bf801-2dc9-47b7-bcad-d43991e8aeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_clusters': 2, 'max_iter': 20, 'tol': 0.0001, 'verbose': False, 'random_state': 1, 'init': 'scalable-k-means++', 'n_init': 1, 'oversampling_factor': 2.0, 'max_samples_per_batch': 32768}\n"
     ]
    }
   ],
   "source": [
    "if SPARK_RAPIDS_ML:\n",
    "    print(kmeans.cuml_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6b7c2bb5-c827-4df5-bc1a-6275775cf1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans_a3ac1db29183"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.setFeaturesCol(\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f0aa3a31-c619-4201-81c7-09bbf566e2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model = kmeans.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d8e06e0c-302f-441b-9d74-de0b1b780094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'euclidean'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.getDistanceMeasure()\n",
    "# 'euclidean'\n",
    "# Note: this is not used in spark_rapids_ml (may be implied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f3cc0c6a-a09a-4da7-b037-b4101244b780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeansModel_38072dd10271"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.setPredictionCol(\"newPrediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3915c572-5250-4005-857b-d3beacf03d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distanceMeasure: the distance measure. Supported options: 'euclidean' and 'cosine'. (default: euclidean)\n",
      "featuresCol: features column name. (default: features, current: features)\n",
      "featuresCols: features column names for multi-column input. (undefined)\n",
      "initMode: The initialization algorithm. This can be either \"random\" to choose random points as initial cluster centers, or \"k-means||\" to use a parallel variant of k-means++ (default: k-means||)\n",
      "initSteps: The number of steps for k-means|| initialization mode. Must be > 0. (default: 2)\n",
      "k: The number of clusters to create. Must be > 1. (default: 2, current: 2)\n",
      "maxBlockSizeInMB: maximum memory in MB for stacking input data into blocks. Data is stacked within partitions. If more than remaining data size in a partition then it is adjusted to the data size. Default 0.0 represents choosing optimal value, depends on specific algorithm. Must be >= 0. (default: 0.0)\n",
      "maxIter: max number of iterations (>= 0). (default: 20)\n",
      "num_workers: (cuML) number of Spark cuML workers, where each cuML worker corresponds to one Spark task. (default: 1)\n",
      "predictionCol: prediction column name. (default: prediction, current: newPrediction)\n",
      "seed: random seed. (default: 1909113551, current: 1)\n",
      "solver: The solver algorithm for optimization. Supported options: auto, row, block. (default: auto)\n",
      "tol: the convergence tolerance for iterative algorithms (>= 0). (default: 0.0001)\n",
      "weightCol: weight column name. If this is not set or empty, we treat all instance weights as 1.0. (undefined)\n"
     ]
    }
   ],
   "source": [
    "print(model.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0f688351-cf4f-449b-b0ef-7735779e4d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_clusters': 2, 'max_iter': 20, 'tol': 0.0001, 'verbose': False, 'random_state': 1, 'init': 'scalable-k-means++', 'n_init': 1, 'oversampling_factor': 2.0, 'max_samples_per_batch': 32768}\n"
     ]
    }
   ],
   "source": [
    "if SPARK_RAPIDS_ML:\n",
    "    print(model.cuml_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0a23fe30-d6c3-4e60-b444-9943ca0efdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PYSPARK:\n",
    "    model.predict(df.head().features)\n",
    "    # 0\n",
    "else:\n",
    "    # NotImplementedError: 'predict' method is not supported, use 'transform' instead.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "51d7bf2a-7fea-4e06-bea1-b9c28d3fa348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers = model.clusterCenters()\n",
    "len(centers)\n",
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5e3a9f42-6215-4523-92a0-f2d54108f702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[8.5, 8.5], [0.5, 0.5]]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers\n",
    "# [array([0.5, 0.5]), array([8.5, 8.5])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cc07f4d2-c338-45c0-90eb-50d8353e98da",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PYSPARK:\n",
    "    transformed = model.transform(df).select(\"features\", \"newPrediction\")\n",
    "else:\n",
    "    # AnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `features` cannot be resolved. Did you mean one of the following? [`prediction`].;\n",
    "    # 'Project ['features, 'newPrediction]\n",
    "    # +- MapInPandas _transform_udf(weighCol#1, features#29)#35, [prediction#36]\n",
    "    #    +- Project [weighCol#1, features#29]\n",
    "    #       +- Project [cuml_values_c3BhcmtjdW1sCg==#26, weighCol#1, UDF(cuml_values_c3BhcmtjdW1sCg==#26) AS features#29]\n",
    "    #          +- Project [features#0 AS cuml_values_c3BhcmtjdW1sCg==#26, weighCol#1]\n",
    "    #             +- Repartition 1, true\n",
    "    #                +- LogicalRDD [features#0, weighCol#1], false    \n",
    "    transformed = model.transform(df)\n",
    "    \n",
    "rows = transformed.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f5030d2c-aeaa-473e-be60-da10444ffe3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------------+\n",
      "|weighCol|  features|newPrediction|\n",
      "+--------+----------+-------------+\n",
      "|     2.0|[0.0, 0.0]|            1|\n",
      "|     2.0|[1.0, 1.0]|            1|\n",
      "|     2.0|[9.0, 8.0]|            0|\n",
      "|     2.0|[8.0, 9.0]|            0|\n",
      "+--------+----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed = model.transform(df)\n",
    "transformed.show()\n",
    "# +---------+--------+-------------+\n",
    "# | features|weighCol|newPrediction|\n",
    "# +---------+--------+-------------+\n",
    "# |[0.0,0.0]|     2.0|            0|\n",
    "# |[1.0,1.0]|     2.0|            0|\n",
    "# |[9.0,8.0]|     2.0|            1|\n",
    "# |[8.0,9.0]|     2.0|            1|\n",
    "# +---------+--------+-------------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "649c9e6d-7545-4f6b-ae83-4b89a8e16b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows[0].newPrediction == rows[1].newPrediction\n",
    "# True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a43c8a3f-e2bf-4911-aa92-679e74184b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows[2].newPrediction == rows[3].newPrediction\n",
    "# True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fa25602c-051d-4528-8945-3ee52a078d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hasSummary\n",
    "# True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "943cbdaf-f02d-4767-9392-cac19d54e190",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PYSPARK:\n",
    "    summary = model.summary\n",
    "    summary.k\n",
    "    # 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eecb8320-cb7c-463c-b61a-5b11b6b1443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PYSPARK:\n",
    "    summary.clusterSizes\n",
    "    # [2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6d93e6b6-9911-46dc-b09e-a12726ef955d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PYSPARK:\n",
    "    summary.trainingCost\n",
    "    # 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a919fe43-1cab-4f47-8b65-6611fde97263",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_path = \"/tmp\"\n",
    "kmeans_path = temp_path + \"/kmeans\"\n",
    "shutil.rmtree(kmeans_path, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "698fe092-7d62-4e16-9b6a-6325956437de",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.save(kmeans_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "351c1ebe-fffa-4d57-9982-06d2c3baacdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans2 = KMeans.load(kmeans_path)\n",
    "kmeans2.getK()\n",
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0a5f8f09-f9ae-4a48-b1b8-4b4b21f49af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_clusters': 2, 'max_iter': 20, 'tol': 0.0001, 'verbose': False, 'random_state': 1, 'init': 'scalable-k-means++', 'n_init': 1, 'oversampling_factor': 2.0, 'max_samples_per_batch': 32768}\n",
      "{'n_clusters': 2, 'max_iter': 20, 'tol': 0.0001, 'verbose': False, 'random_state': 1, 'init': 'scalable-k-means++', 'n_init': 1, 'oversampling_factor': 2.0, 'max_samples_per_batch': 32768}\n"
     ]
    }
   ],
   "source": [
    "# confirm saved estimator cuml_params\n",
    "if SPARK_RAPIDS_ML:\n",
    "    print(kmeans.cuml_params)\n",
    "    print(kmeans2.cuml_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c3849ee2-3785-468f-a92b-f770d0ac5e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = temp_path + \"/kmeans_model\"\n",
    "shutil.rmtree(model_path, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1de7c77a-42a1-40fc-a2e8-afd287ed99f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "13e4b816-1cbb-406d-860b-73bdc054b908",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = KMeansModel.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "45141fb8-0ded-4813-9ae0-b064954b6690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_clusters': 2, 'max_iter': 20, 'tol': 0.0001, 'verbose': False, 'random_state': 1, 'init': 'scalable-k-means++', 'n_init': 1, 'oversampling_factor': 2.0, 'max_samples_per_batch': 32768}\n",
      "{'n_clusters': 2, 'max_iter': 20, 'tol': 0.0001, 'verbose': False, 'random_state': 1, 'init': 'scalable-k-means++', 'n_init': 1, 'oversampling_factor': 2.0, 'max_samples_per_batch': 32768}\n"
     ]
    }
   ],
   "source": [
    "# confirm saved model cuml_params\n",
    "if SPARK_RAPIDS_ML:\n",
    "    print(model.cuml_params)\n",
    "    print(model2.cuml_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b6abdfca-a24d-43e9-a2a7-88499429ce25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.hasSummary\n",
    "# False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "367a1164-f60e-4507-9e53-a7a99cc812aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.clusterCenters()[0] == model2.clusterCenters()[0]\n",
    "# array([ True,  True], dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "54baf487-9c5f-4959-8c36-02a1d492336e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.clusterCenters()[1] == model2.clusterCenters()[1]\n",
    "# array([ True,  True], dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4a6c8a6d-92eb-4288-9fe0-79ab9e903332",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transform(df).take(1) == model2.transform(df).take(1)\n",
    "# True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fa86508c-685e-4dcb-8280-68b20c6d485d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(weighCol=2.0, features=[0.0, 0.0], newPrediction=1)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transform(df).take(1)\n",
    "# [Row(features=DenseVector([0.0, 0.0]), weighCol=2.0, newPrediction=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4fd543e5-5892-4013-b97a-99d6580e0877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(features=DenseVector([0.0, 0.0]), weighCol=2.0)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(1)\n",
    "# [Row(features=DenseVector([0.0, 0.0]), weighCol=2.0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea1d778-7431-4137-a704-ae42ad6f1ea2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LinearRegression\n",
    "\n",
    "From: https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.LinearRegression.html#pyspark.ml.regression.LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "37e14233-ed46-4c33-919c-5b5afd16aad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PYSPARK = False\n",
    "SPARK_RAPIDS_ML = not PYSPARK\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a2b9e647-50c3-4bd0-874b-8989e467185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PYSPARK:\n",
    "    from pyspark.ml.regression import LinearRegression, LinearRegressionModel\n",
    "else:\n",
    "    from spark_rapids_ml.regression import LinearRegression, LinearRegressionModel\n",
    "\n",
    "from pyspark.ml.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1c6e94f2-9e9b-45b5-82b6-3bd61a410b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+\n",
      "|label|weight| features|\n",
      "+-----+------+---------+\n",
      "|  1.0|   2.0|    [1.0]|\n",
      "|  0.0|   2.0|(1,[],[])|\n",
      "+-----+------+---------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StructType([StructField('label', DoubleType(), True), StructField('weight', DoubleType(), True), StructField('features', VectorUDT(), True)])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.createDataFrame([\n",
    "    (1.0, 2.0, Vectors.dense(1.0)),\n",
    "    (0.0, 2.0, Vectors.sparse(1, [], []))], [\"label\", \"weight\", \"features\"])\n",
    "\n",
    "df.show(); df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3b4a74fc-f83c-413f-8302-c53a39153ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if PYSPARK:\n",
    "    lr = LinearRegression(regParam=0.0, solver=\"normal\", weightCol=\"weight\")\n",
    "else:\n",
    "    # 'solver: normal' gets value mapped to 'solver: eig'\n",
    "    # 'weightCol` is explicitly not supported\n",
    "    lr = LinearRegression(regParam=0.0, solver=\"normal\")\n",
    "\n",
    "lr.setMaxIter(5)\n",
    "lr.getMaxIter()\n",
    "# 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8895e735-b09f-49b2-a342-29f2405e94f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggregationDepth: suggested depth for treeAggregate (>= 2). (default: 2)\n",
      "elasticNetParam: the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty. (default: 0.0)\n",
      "epsilon: The shape parameter to control the amount of robustness. Must be > 1.0. Only valid when loss is huber (default: 1.35)\n",
      "featuresCol: features column name. (default: features)\n",
      "featuresCols: features column names for multi-column input. (undefined)\n",
      "fitIntercept: whether to fit an intercept term. (default: True)\n",
      "labelCol: label column name. (default: label)\n",
      "loss: The loss function to be optimized. Supported options: squaredError, huber. (default: squaredError)\n",
      "maxBlockSizeInMB: maximum memory in MB for stacking input data into blocks. Data is stacked within partitions. If more than remaining data size in a partition then it is adjusted to the data size. Default 0.0 represents choosing optimal value, depends on specific algorithm. Must be >= 0. (default: 0.0)\n",
      "maxIter: max number of iterations (>= 0). (default: 100, current: 5)\n",
      "num_workers: (cuML) number of Spark cuML workers, where each cuML worker corresponds to one Spark task. (default: 1)\n",
      "predictionCol: prediction column name. (default: prediction)\n",
      "regParam: regularization parameter (>= 0). (default: 0.0, current: 0.0)\n",
      "solver: The solver algorithm for optimization. Supported options: auto, normal, l-bfgs. (default: auto, current: normal)\n",
      "standardization: whether to standardize the training features before fitting the model. (default: True)\n",
      "tol: the convergence tolerance for iterative algorithms (>= 0). (default: 1e-06)\n",
      "weightCol: weight column name. If this is not set or empty, we treat all instance weights as 1.0. (undefined)\n"
     ]
    }
   ],
   "source": [
    "print(lr.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8c766d10-6c69-448a-be07-d43bca4de6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'eig', 'fit_intercept': True, 'normalize': True, 'verbose': False, 'alpha': 0.0, 'solver': 'eig', 'loss': 'squared_loss', 'l1_ratio': 0.0, 'max_iter': 5, 'tol': 1e-06, 'shuffle': True}\n"
     ]
    }
   ],
   "source": [
    "if SPARK_RAPIDS_ML:\n",
    "    print(lr.cuml_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "50d3e6b0-14f6-4e9f-85c5-3fab4335f49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.setRegParam(0.1)\n",
    "lr.getRegParam()\n",
    "# 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e35968e1-8af4-4664-994c-83fab9dae385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression_1733189a05f6"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.setRegParam(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9f8280b3-a086-472d-8e87-7d52d9cd72d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggregationDepth: suggested depth for treeAggregate (>= 2). (default: 2)\n",
      "elasticNetParam: the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty. (default: 0.0)\n",
      "epsilon: The shape parameter to control the amount of robustness. Must be > 1.0. Only valid when loss is huber (default: 1.35)\n",
      "featuresCol: features column name. (default: features)\n",
      "featuresCols: features column names for multi-column input. (undefined)\n",
      "fitIntercept: whether to fit an intercept term. (default: True)\n",
      "labelCol: label column name. (default: label)\n",
      "loss: The loss function to be optimized. Supported options: squaredError, huber. (default: squaredError)\n",
      "maxBlockSizeInMB: maximum memory in MB for stacking input data into blocks. Data is stacked within partitions. If more than remaining data size in a partition then it is adjusted to the data size. Default 0.0 represents choosing optimal value, depends on specific algorithm. Must be >= 0. (default: 0.0)\n",
      "maxIter: max number of iterations (>= 0). (default: 100, current: 5)\n",
      "num_workers: (cuML) number of Spark cuML workers, where each cuML worker corresponds to one Spark task. (default: 1)\n",
      "predictionCol: prediction column name. (default: prediction)\n",
      "regParam: regularization parameter (>= 0). (default: 0.0, current: 0.0)\n",
      "solver: The solver algorithm for optimization. Supported options: auto, normal, l-bfgs. (default: auto, current: normal)\n",
      "standardization: whether to standardize the training features before fitting the model. (default: True)\n",
      "tol: the convergence tolerance for iterative algorithms (>= 0). (default: 1e-06)\n",
      "weightCol: weight column name. If this is not set or empty, we treat all instance weights as 1.0. (undefined)\n"
     ]
    }
   ],
   "source": [
    "print(lr.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8905c16f-5211-4a12-9863-6bdb31ffe54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'eig', 'fit_intercept': True, 'normalize': True, 'verbose': False, 'alpha': 0.0, 'solver': 'eig', 'loss': 'squared_loss', 'l1_ratio': 0.0, 'max_iter': 5, 'tol': 1e-06, 'shuffle': True}\n"
     ]
    }
   ],
   "source": [
    "if SPARK_RAPIDS_ML:\n",
    "    print(lr.cuml_params)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6778e477-b4ef-4bca-b739-ddac73a7baa2",
   "metadata": {},
   "source": [
    "# RuntimeError: LinearRegression doesn't support training data with 1 column\n",
    "model = lr.fit(df)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8048ad8b-f7f8-4134-9506-b6a4b562f11e",
   "metadata": {},
   "source": [
    "model.setFeaturesCol(\"features\")\n",
    "model.setPredictionCol(\"newPrediction\")\n",
    "model.getMaxIter()\n",
    "# 5"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4f3398d6-225c-4068-ae04-117983a17cb9",
   "metadata": {},
   "source": [
    "model.getMaxBlockSizeInMB()\n",
    "# 0.0"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ac49b135-265f-4dc6-99fb-da8c949b18dc",
   "metadata": {},
   "source": [
    "test0 = spark.createDataFrame([(Vectors.dense(1.0),)], [\"features\"])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "92ec10b2-ebb7-4d71-8701-ddd47caf0a0d",
   "metadata": {},
   "source": [
    "abs(model.predict(test0.head().features) - (-1.0)) < 0.001"
   ]
  },
  {
   "cell_type": "raw",
   "id": "18bf08e3-6828-4183-a1dd-1dce7860862d",
   "metadata": {},
   "source": [
    "abs(model.transform(test0).head().newPrediction - (-1.0)) < 0.001\n",
    "# True"
   ]
  },
  {
   "cell_type": "raw",
   "id": "795f6371-9bca-43b8-8b80-038e7f843d58",
   "metadata": {},
   "source": [
    "abs(model.coefficients[0] - 1.0) < 0.001\n",
    "# True"
   ]
  },
  {
   "cell_type": "raw",
   "id": "242f5137-32a6-4b18-bbfe-68e3d1deffb7",
   "metadata": {},
   "source": [
    "abs(model.intercept - 0.0) < 0.001\n",
    "# True"
   ]
  },
  {
   "cell_type": "raw",
   "id": "051b3906-1fe7-4d89-b6ba-8f49d4a6e992",
   "metadata": {},
   "source": [
    "test1 = spark.createDataFrame([(Vectors.sparse(1, [0], [1.0]),)], [\"features\"])\n",
    "abs(model.transform(test1).head().newPrediction - 1.0) < 0.001\n",
    "# True"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a77c2378-ffa1-470e-899f-ea53ee382c12",
   "metadata": {},
   "source": [
    "lr.setParams(featuresCol=\"vector\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dbf88387-6184-4212-ad11-7450ae53e6af",
   "metadata": {},
   "source": [
    "temp_path = \"/tmp\"\n",
    "lr_path = temp_path + \"/lr\"\n",
    "shutil.rmtree(lr_path, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5991d1b8-6df5-483b-9cd6-0f198b9f7cbf",
   "metadata": {},
   "source": [
    "lr.save(lr_path)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6298ac89-3d22-4e6b-a410-2a435c722b8d",
   "metadata": {},
   "source": [
    "lr2 = LinearRegression.load(lr_path)\n",
    "lr2.getMaxIter()\n",
    "# 5"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f73ef4d-f781-4057-925b-10fa8ad1978c",
   "metadata": {},
   "source": [
    "model_path = temp_path + \"/lr_model\"\n",
    "shutil.rmtree(model_path, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a8237d0b-309b-4a44-801b-038703c80688",
   "metadata": {},
   "source": [
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8805c6e6-0dca-4c67-83c1-d06d867eaa81",
   "metadata": {},
   "source": [
    "model2 = LinearRegressionModel.load(model_path)\n",
    "model.coefficients[0] == model2.coefficients[0]\n",
    "# True"
   ]
  },
  {
   "cell_type": "raw",
   "id": "54efe8a1-417f-4650-bc1c-cade889b27c3",
   "metadata": {},
   "source": [
    "model.intercept == model2.intercept\n",
    "# True"
   ]
  },
  {
   "cell_type": "raw",
   "id": "54dc8756-d161-4a81-a514-c8b465ed4753",
   "metadata": {},
   "source": [
    "model.transform(test0).take(1) == model2.transform(test0).take(1)\n",
    "# True"
   ]
  },
  {
   "cell_type": "raw",
   "id": "df6c4f1f-e7c4-4496-965d-8b5e8c601cac",
   "metadata": {},
   "source": [
    "model.numFeatures\n",
    "# 1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1bc1b5b1-0e5e-4262-97b3-00cf8725b550",
   "metadata": {},
   "source": [
    "shutil.rmtree(model_path + \"_2\", ignore_errors=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea5db433-f36d-4bba-b626-eadc93021f40",
   "metadata": {},
   "source": [
    "model.write().format(\"pmml\").save(model_path + \"_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b027a046-1d81-4afe-b2f0-d5a746a4afbd",
   "metadata": {},
   "source": [
    "## LinearRegression (custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4cf7b91a-b2b7-4bf3-b41f-dae23a1f173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PYSPARK = False\n",
    "SPARK_RAPIDS_ML = not PYSPARK\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "15e16933-0673-41b6-ab23-a85e8951042a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from pyspark.ml.functions import array_to_vector\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.sql.functions import array, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "630856e5-1431-4cd7-bc03-9f1fb2a0d8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PYSPARK:\n",
    "    from pyspark.ml.regression import LinearRegression, LinearRegressionModel\n",
    "else:\n",
    "    from spark_rapids_ml.regression import LinearRegression, LinearRegressionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7130d47c-f6b4-436d-ab72-f0d82f29caf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(\n",
    "    [[-0.20515826,  1.4940791 ],\n",
    "     [ 0.12167501,  0.7610377 ],\n",
    "     [ 1.4542735,   0.14404356],\n",
    "     [-0.85409576,  0.3130677 ],\n",
    "     [ 2.2408931,   0.978738  ],\n",
    "     [-0.1513572,   0.95008844],\n",
    "     [-0.9772779,   1.867558  ],\n",
    "     [ 0.41059852, -0.10321885]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0335f18f-d139-41ca-b094-047e40a5e77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([2.0374513, 22.403986, 139.4456, -76.19584, 225.72075, -0.6784152, -65.54835, 37.30829])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "30c9d584-66c2-43a9-9cd4-aafad4bb2e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\"c0\", \"c1\"]\n",
    "label_col = \"label_col\"\n",
    "schema = [\"c0 float, c1 float, label_col float\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "11f4a34c-cc6c-440d-b289-e59fa2c5a57a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['c0', 'c1'], 'label_col')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols, label_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "29e50450-1869-496e-a5ff-b6078c85b454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c0 float, c1 float, label_col float']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2ec95d8d-30e0-4faf-b5ff-9516a084c97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(\n",
    "    np.concatenate((X, y.reshape(8, 1)), axis=1).tolist(),\n",
    "    \",\".join(schema),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9d049829-6e03-485c-8b24-6aba05ac5834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+----------+\n",
      "|         c0|         c1| label_col|\n",
      "+-----------+-----------+----------+\n",
      "|-0.20515826|  1.4940791| 2.0374513|\n",
      "| 0.12167501|  0.7610377| 22.403986|\n",
      "|  1.4542735| 0.14404356|  139.4456|\n",
      "|-0.85409576|  0.3130677| -76.19584|\n",
      "|  2.2408931|   0.978738| 225.72075|\n",
      "| -0.1513572| 0.95008844|-0.6784152|\n",
      "| -0.9772779|   1.867558| -65.54835|\n",
      "| 0.41059852|-0.10321885|  37.30829|\n",
      "+-----------+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c198fe13-d403-403c-8be7-cca8c1e0491e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "| label_col|            features|\n",
      "+----------+--------------------+\n",
      "| 2.0374513|[-0.20515826, 1.4...|\n",
      "| 22.403986|[0.12167501, 0.76...|\n",
      "|  139.4456|[1.4542735, 0.144...|\n",
      "| -76.19584|[-0.85409576, 0.3...|\n",
      "| 225.72075|[2.2408931, 0.978...|\n",
      "|-0.6784152|[-0.1513572, 0.95...|\n",
      "| -65.54835|[-0.9772779, 1.86...|\n",
      "|  37.30829|[0.41059852, -0.1...|\n",
      "+----------+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StructType([StructField('label_col', FloatType(), True), StructField('features', ArrayType(FloatType(), True), False)])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.withColumn(\"features\", array(*feature_cols)).drop(*feature_cols)\n",
    "df.show(); df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bb9dddbd-cdac-4d15-84d1-f006a97454e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PYSPARK:\n",
    "    # requires VectorUDT\n",
    "    df = df.withColumn(\"features_vec\", array_to_vector(\"features\")).drop(\"features\").withColumnRenamed(\"features_vec\", \"features\")\n",
    "    df.show()\n",
    "    print(df.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "72811822-4182-4403-95b1-6bf643d1b7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ebde896d-8b40-4ba4-ae98-1af2e1a9f787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression_e39e50da1e7e"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.setFeaturesCol(\"features\")\n",
    "lr.setRegParam(0.0)\n",
    "lr.setLabelCol(\"label_col\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "64dee2e1-91ee-490e-88cd-235f4e625361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggregationDepth: suggested depth for treeAggregate (>= 2). (default: 2)\n",
      "elasticNetParam: the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty. (default: 0.0)\n",
      "epsilon: The shape parameter to control the amount of robustness. Must be > 1.0. Only valid when loss is huber (default: 1.35)\n",
      "featuresCol: features column name. (default: features, current: features)\n",
      "featuresCols: features column names for multi-column input. (undefined)\n",
      "fitIntercept: whether to fit an intercept term. (default: True)\n",
      "labelCol: label column name. (default: label, current: label_col)\n",
      "loss: The loss function to be optimized. Supported options: squaredError, huber. (default: squaredError)\n",
      "maxBlockSizeInMB: maximum memory in MB for stacking input data into blocks. Data is stacked within partitions. If more than remaining data size in a partition then it is adjusted to the data size. Default 0.0 represents choosing optimal value, depends on specific algorithm. Must be >= 0. (default: 0.0)\n",
      "maxIter: max number of iterations (>= 0). (default: 100)\n",
      "num_workers: (cuML) number of Spark cuML workers, where each cuML worker corresponds to one Spark task. (default: 1)\n",
      "predictionCol: prediction column name. (default: prediction)\n",
      "regParam: regularization parameter (>= 0). (default: 0.0, current: 0.0)\n",
      "solver: The solver algorithm for optimization. Supported options: auto, normal, l-bfgs. (default: auto)\n",
      "standardization: whether to standardize the training features before fitting the model. (default: True)\n",
      "tol: the convergence tolerance for iterative algorithms (>= 0). (default: 1e-06)\n",
      "weightCol: weight column name. If this is not set or empty, we treat all instance weights as 1.0. (undefined)\n"
     ]
    }
   ],
   "source": [
    "print(lr.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "68a11804-77ad-4d44-a6bd-d3912dc835c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'eig', 'fit_intercept': True, 'normalize': True, 'verbose': False, 'alpha': 0.0, 'solver': 'eig', 'loss': 'squared_loss', 'l1_ratio': 0.0, 'max_iter': 100, 'tol': 1e-06, 'shuffle': True}\n"
     ]
    }
   ],
   "source": [
    "if SPARK_RAPIDS_ML:\n",
    "    print(lr.cuml_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "694314a4-a707-4b1b-86f5-ce645ae881bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lr_model = lr.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9bd54034-cd9d-486a-ab21-d5819d7264a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[94.46691131591797, 14.33534049987793]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.coefficients\n",
    "# [94.46689350900762,14.33532962562045]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af8dffc-44a2-4cce-9bed-31fd228d146b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
