{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a7c21330-7326-4d98-9351-d1b2e4c6143c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "291da378-0e9b-4b53-bf9e-b78c35631f1d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "n_rows = 50000\n",
    "n_cols = 300\n",
    "dtype='float32'\n",
    "X, y = make_regression(n_samples=n_rows, n_features=n_cols, random_state=1)\n",
    "X = X.astype(dtype)\n",
    "y = y.astype(dtype)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a9ae1eaf-a6d7-467d-88c0-644ae814c488",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Convert dataset to Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a9ae1eaf-a6d7-467d-88c0-644ae814c488",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pd_data_train = pd.DataFrame({\"features\": list(X_train), \"label\": y_train})\n",
    "pd_data_test = pd.DataFrame({\"features\": list(X_test), \"label\": y_test})\n",
    "df_train = spark.createDataFrame(pd_data_train)\n",
    "df_test = spark.createDataFrame(pd_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressor builder\n",
    "We will use this function to build both the Spark RAPIDS ML (GPU) and Spark ML (CPU) random forest regressor objects, demonstrating the common API, and verify they yield similar performance on our synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rf_regressor(estimator_class):\n",
    "    return ( estimator_class()\n",
    "                .setFeaturesCol(\"features\")\n",
    "                .setLabelCol(\"label\")\n",
    "                .setFeatureSubsetStrategy(\"all\")\n",
    "                .setNumTrees(50)\n",
    "                .setMaxDepth(9)\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "90b36ddc-2f90-409b-a213-3f319c736134",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Spark RAPIDS ML (GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: spark-rapids-ml RandomForestRegressor leverages RAPIDS cuML MNMG implementation and inherits its current *embarrassingly parallel* implementation.   See RAPIDS API docs for more information:  https://docs.rapids.ai/api/cuml/stable/api/#cuml.dask.ensemble.RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "559be116-df65-4d64-b549-6f1e5f813b08",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from spark_rapids_ml.regression import RandomForestRegressor\n",
    "gpu_rf_regressor = build_rf_regressor(RandomForestRegressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a5a2cac5-18cd-450a-8571-195be588a361",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Spark Rapids ML estimator can be persisted and reloaded similarly to Spark ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_path = \"/tmp/spark-rapids-ml-rf-regressor-estimator\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "798f5b5b-cfa6-45e4-aa18-40c0142e894a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gpu_rf_regressor.write().overwrite().save(estimator_path)\n",
    "gpu_rf_regressor_loaded = RandomForestRegressor.load(estimator_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "209d8f9c-1d1c-4bdd-880c-10e46f9d0c49",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "gpu_model = gpu_rf_regressor_loaded.fit(df_train)\n",
    "print(f\"Fit took: {time.time() - start_time} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db84a983-a64f-462b-813b-7b7ba629d18e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gpu_model.getNumTrees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/tmp/spark-rapids-ml-rf-regressor-model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6874b600-707d-48a7-b780-5d4e939a746b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gpu_model.write().overwrite().save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "441c8635-9070-426f-8626-7083f34b7e71",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gpu_model_loaded = gpu_model.read().load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48f7975c-f2ce-471d-aa8e-8dc678a44f37",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gpu_model_loaded.getNumTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c3bfc179-e702-4198-8122-3a8ba98113a4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "transformed_df = gpu_model_loaded.setPredictionCol(\"prediction\").transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de0ce32d-3d09-4e82-b6a7-26978925181a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "transformed_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c63b707-0e00-4961-8a76-82f347886b83",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "transformed_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a7c5d3b5-ecb0-435a-8976-bc18a28e3e04",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "transformed_df.select(\"features\",\"label\",\"prediction\").sort(\"features\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the RMSE on the test set of the GPU trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = (\n",
    "            RegressionEvaluator()\n",
    "                .setPredictionCol(\"prediction\")\n",
    "                .setLabelCol(\"label\")\n",
    "            )\n",
    "print(f\"rmse: {evaluator.evaluate(transformed_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the RMSE is smaller than the standard deviation of the label column, indicating that the model is making non-trivial predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import stddev\n",
    "\n",
    "print(f'label stddev: {transformed_df.select(stddev(\"label\").alias(\"stddev\")).toPandas()[\"stddev\"][0]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ccc646a3-6063-42f4-8909-03c285ce55d6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Spark ML (CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "122a7ab9-d142-4244-b79c-bbf7e6eb05e9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "cpu_rf_regressor = build_rf_regressor(RandomForestRegressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd173dd2-7058-4d73-a969-c20e9f55e3e4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Convert array sql type to VectorUDT expected by Spark ML (Note: Spark RAPIDS ML also accepts VectorUDT Dataframes in addition to array type Dataframe above, along with a scalar column format - see docs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f8a18da-17a5-4fcc-b2a5-604ea1088e1b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.functions import array_to_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b9882dae-8c66-4e4d-8164-36040e2f0f3b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "vector_df_train = df_train.select(array_to_vector(df_train.features).alias(\"features\"),\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a48fdc86-e827-4545-a923-109519c675d6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "cpu_model = cpu_rf_regressor.fit(vector_df_train)\n",
    "print(f\"Fit took: {time.time() - start_time} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7fb9b7ea-15db-4678-8087-40b69c13c7bb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cpu_model.getNumTrees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_df_test = df_test.select(array_to_vector(df_test.features).alias(\"features\"),\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec2a3245-fa44-4b08-b4f0-dc9c16b1528e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cpu_transformed_df = cpu_model.setPredictionCol(\"prediction\").transform(vector_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2c02f6f1-36ac-4a02-995f-6ad68ee38cec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cpu_transformed_df.select(\"features\",\"label\",\"prediction\").sort(\"features\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test set RMSEs of GPU model above and CPU model below are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"rmse: {evaluator.evaluate(cpu_transformed_df)}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "spark-rapids-ml-lr-demo",
   "notebookOrigID": 1026070411409745,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
