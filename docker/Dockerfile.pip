#
# Copyright (c) 2023, NVIDIA CORPORATION.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

ARG CUDA_VERSION=11.8.0
FROM nvidia/cuda:${CUDA_VERSION}-devel-ubuntu20.04

ARG PYSPARK_VERSION=3.3.1
ARG RAPIDS_VERSION=23.6.0

# Install packages to build spark-rapids-ml
RUN apt-get update -y \
    && DEBIAN_FRONTEND=noninteractive TZ=Etc/UTC apt install -y openjdk-8-jdk \
    && rm -rf /var/lib/apt/lists

RUN apt-get update -y \
    && apt install -y git numactl python3.8 python3.8-venv python3-pip python-is-python3 software-properties-common wget zip \
    && python -m pip install --upgrade pip \
    && rm -rf /var/lib/apt/lists

# install RAPIDS
# using ~= pulls in micro version patches
RUN pip install --no-cache-dir \
    cudf-cu11~=${RAPIDS_VERSION} \
    cuml-cu11~=${RAPIDS_VERSION} \
    dask-cudf-cu11~=${RAPIDS_VERSION} \
    pylibraft-cu11~=${RAPIDS_VERSION} \
    raft-dask-cu11~=${RAPIDS_VERSION} \
    rmm-cu11~=${RAPIDS_VERSION} \
    --extra-index-url=https://pypi.nvidia.com

# install python dependencies
RUN pip install --no-cache-dir pyspark==${PYSPARK_VERSION} "scikit-learn>=1.2.1" \
    && pip install --no-cache-dir "black>=23.1.0" "build>=0.10.0" "isort>=5.12.0" "mypy>=1.0.0" \
    numpydoc pydata-sphinx-theme pylint pytest "sphinx<6.0" "twine>=4.0.0"

# Config JAVA_HOME
ENV JAVA_HOME /usr/lib/jvm/java-1.8.0-openjdk-amd64

### END OF CACHE ###

#ARG RAPIDS_ML_VER=main
#RUN git clone -b branch-$RAPIDS_ML_VER https://github.com/NVIDIA/spark-rapids-ml.git
COPY . /spark-rapids-ml
WORKDIR /spark-rapids-ml/python

# install spark-rapids-ml with requirements_dev.txt (in case it has diverged from cache)
RUN pip install --no-cache-dir -r requirements_dev.txt \
    && pip install --no-cache-dir -e .

SHELL ["/bin/bash", "-c"]
